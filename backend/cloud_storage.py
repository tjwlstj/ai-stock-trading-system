"""
AI Stock Trading System - Cloud Storage Module
í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€ ì—°ë™ ë° ë°ì´í„° ë°±ì—… ëª¨ë“ˆ
"""

import os
import json
import boto3
import sqlite3
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import logging
from botocore.exceptions import ClientError, NoCredentialsError

logger = logging.getLogger(__name__)

class CloudStorageManager:
    """í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, bucket_name: str = "ai-stock-trading-data", 
                 aws_access_key: Optional[str] = None,
                 aws_secret_key: Optional[str] = None,
                 region: str = "us-east-1"):
        """
        í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        
        Args:
            bucket_name: S3 ë²„í‚· ì´ë¦„
            aws_access_key: AWS ì•¡ì„¸ìŠ¤ í‚¤ (í™˜ê²½ë³€ìˆ˜ì—ì„œ ìë™ ë¡œë“œ)
            aws_secret_key: AWS ì‹œí¬ë¦¿ í‚¤ (í™˜ê²½ë³€ìˆ˜ì—ì„œ ìë™ ë¡œë“œ)
            region: AWS ë¦¬ì „
        """
        self.bucket_name = bucket_name
        self.region = region
        
        # AWS ìê²©ì¦ëª… ì„¤ì •
        try:
            if aws_access_key and aws_secret_key:
                self.s3_client = boto3.client(
                    's3',
                    aws_access_key_id=aws_access_key,
                    aws_secret_access_key=aws_secret_key,
                    region_name=region
                )
            else:
                # í™˜ê²½ë³€ìˆ˜ë‚˜ IAM ì—­í• ì—ì„œ ìê²©ì¦ëª… ë¡œë“œ
                self.s3_client = boto3.client('s3', region_name=region)
            
            self.storage_available = True
            logger.info("í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€ ì—°ê²° ì„±ê³µ")
            
        except (NoCredentialsError, Exception) as e:
            logger.warning(f"í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€ ì—°ê²° ì‹¤íŒ¨: {str(e)}")
            self.s3_client = None
            self.storage_available = False
    
    def create_bucket_if_not_exists(self) -> bool:
        """
        ë²„í‚·ì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±
        
        Returns:
            ìƒì„± ì„±ê³µ ì—¬ë¶€
        """
        if not self.storage_available:
            return False
        
        try:
            # ë²„í‚· ì¡´ì¬ í™•ì¸
            self.s3_client.head_bucket(Bucket=self.bucket_name)
            logger.info(f"ë²„í‚· '{self.bucket_name}' ì´ë¯¸ ì¡´ì¬")
            return True
            
        except ClientError as e:
            error_code = int(e.response['Error']['Code'])
            
            if error_code == 404:
                # ë²„í‚·ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ - ìƒì„± ì‹œë„
                try:
                    if self.region == 'us-east-1':
                        self.s3_client.create_bucket(Bucket=self.bucket_name)
                    else:
                        self.s3_client.create_bucket(
                            Bucket=self.bucket_name,
                            CreateBucketConfiguration={'LocationConstraint': self.region}
                        )
                    
                    logger.info(f"ë²„í‚· '{self.bucket_name}' ìƒì„± ì„±ê³µ")
                    return True
                    
                except ClientError as create_error:
                    logger.error(f"ë²„í‚· ìƒì„± ì‹¤íŒ¨: {str(create_error)}")
                    return False
            else:
                logger.error(f"ë²„í‚· í™•ì¸ ì‹¤íŒ¨: {str(e)}")
                return False
    
    def upload_database_backup(self, db_path: str, backup_name: Optional[str] = None) -> bool:
        """
        ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…ì„ í´ë¼ìš°ë“œì— ì—…ë¡œë“œ
        
        Args:
            db_path: ë¡œì»¬ ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ê²½ë¡œ
            backup_name: ë°±ì—… íŒŒì¼ ì´ë¦„ (ê¸°ë³¸ê°’: íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)
            
        Returns:
            ì—…ë¡œë“œ ì„±ê³µ ì—¬ë¶€
        """
        if not self.storage_available:
            logger.warning("í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ")
            return False
        
        if not os.path.exists(db_path):
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {db_path}")
            return False
        
        if not backup_name:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_name = f"database_backup_{timestamp}.db"
        
        try:
            # S3ì— ì—…ë¡œë“œ
            s3_key = f"backups/{backup_name}"
            self.s3_client.upload_file(db_path, self.bucket_name, s3_key)
            
            logger.info(f"ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ì—…ë¡œë“œ ì„±ê³µ: {s3_key}")
            return True
            
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def upload_analysis_results(self, analysis_data: Dict[str, Any], 
                              symbol: str, analysis_type: str) -> bool:
        """
        ë¶„ì„ ê²°ê³¼ë¥¼ í´ë¼ìš°ë“œì— ì—…ë¡œë“œ
        
        Args:
            analysis_data: ë¶„ì„ ê²°ê³¼ ë°ì´í„°
            symbol: ì£¼ì‹ ì‹¬ë³¼
            analysis_type: ë¶„ì„ íƒ€ì…
            
        Returns:
            ì—…ë¡œë“œ ì„±ê³µ ì—¬ë¶€
        """
        if not self.storage_available:
            return False
        
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            s3_key = f"analysis/{symbol}/{analysis_type}_{timestamp}.json"
            
            # JSON ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            json_data = json.dumps(analysis_data, indent=2, ensure_ascii=False)
            
            # S3ì— ì—…ë¡œë“œ
            self.s3_client.put_object(
                Bucket=self.bucket_name,
                Key=s3_key,
                Body=json_data.encode('utf-8'),
                ContentType='application/json'
            )
            
            logger.info(f"ë¶„ì„ ê²°ê³¼ ì—…ë¡œë“œ ì„±ê³µ: {s3_key}")
            return True
            
        except Exception as e:
            logger.error(f"ë¶„ì„ ê²°ê³¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def download_analysis_results(self, symbol: str, analysis_type: str, 
                                limit: int = 10) -> List[Dict[str, Any]]:
        """
        í´ë¼ìš°ë“œì—ì„œ ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
        
        Args:
            symbol: ì£¼ì‹ ì‹¬ë³¼
            analysis_type: ë¶„ì„ íƒ€ì…
            limit: ìµœëŒ€ ë‹¤ìš´ë¡œë“œ ê°œìˆ˜
            
        Returns:
            ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        if not self.storage_available:
            return []
        
        try:
            prefix = f"analysis/{symbol}/"
            
            # ê°ì²´ ëª©ë¡ ì¡°íšŒ
            response = self.s3_client.list_objects_v2(
                Bucket=self.bucket_name,
                Prefix=prefix,
                MaxKeys=limit
            )
            
            results = []
            
            if 'Contents' in response:
                # ìµœì‹  ìˆœìœ¼ë¡œ ì •ë ¬
                objects = sorted(response['Contents'], 
                               key=lambda x: x['LastModified'], reverse=True)
                
                for obj in objects:
                    if analysis_type in obj['Key']:
                        # ê°ì²´ ë‹¤ìš´ë¡œë“œ
                        obj_response = self.s3_client.get_object(
                            Bucket=self.bucket_name,
                            Key=obj['Key']
                        )
                        
                        # JSON ë°ì´í„° íŒŒì‹±
                        content = obj_response['Body'].read().decode('utf-8')
                        data = json.loads(content)
                        
                        results.append({
                            'key': obj['Key'],
                            'last_modified': obj['LastModified'],
                            'data': data
                        })
            
            logger.info(f"ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(results)}ê°œ")
            return results
            
        except Exception as e:
            logger.error(f"ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def sync_local_to_cloud(self, local_db_path: str) -> Dict[str, Any]:
        """
        ë¡œì»¬ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ í´ë¼ìš°ë“œì™€ ë™ê¸°í™”
        
        Args:
            local_db_path: ë¡œì»¬ ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ
            
        Returns:
            ë™ê¸°í™” ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        if not self.storage_available:
            return {'success': False, 'error': 'Cloud storage not available'}
        
        try:
            # 1. ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ì—…ë¡œë“œ
            backup_success = self.upload_database_backup(local_db_path)
            
            # 2. ìµœê·¼ ë¶„ì„ ê²°ê³¼ë“¤ì„ í´ë¼ìš°ë“œì— ì—…ë¡œë“œ
            uploaded_analyses = 0
            
            with sqlite3.connect(local_db_path) as conn:
                cursor = conn.cursor()
                
                # ìµœê·¼ 24ì‹œê°„ ë‚´ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
                cursor.execute('''
                    SELECT symbol, agent_type, analysis_type, result_data, created_at
                    FROM analysis_results 
                    WHERE created_at >= datetime('now', '-1 day')
                    ORDER BY created_at DESC
                ''')
                
                for row in cursor.fetchall():
                    symbol, agent_type, analysis_type, result_data, created_at = row
                    
                    analysis_data = {
                        'symbol': symbol,
                        'agent_type': agent_type,
                        'analysis_type': analysis_type,
                        'result_data': json.loads(result_data),
                        'created_at': created_at
                    }
                    
                    if self.upload_analysis_results(analysis_data, symbol, 
                                                  f"{agent_type}_{analysis_type}"):
                        uploaded_analyses += 1
            
            return {
                'success': True,
                'backup_uploaded': backup_success,
                'analyses_uploaded': uploaded_analyses,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"í´ë¼ìš°ë“œ ë™ê¸°í™” ì‹¤íŒ¨: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    def get_cloud_storage_stats(self) -> Dict[str, Any]:
        """
        í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€ í†µê³„ ì •ë³´ ë°˜í™˜
        
        Returns:
            í†µê³„ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        if not self.storage_available:
            return {'available': False}
        
        try:
            stats = {'available': True}
            
            # ë°±ì—… íŒŒì¼ ìˆ˜
            backup_response = self.s3_client.list_objects_v2(
                Bucket=self.bucket_name,
                Prefix='backups/'
            )
            stats['backup_count'] = backup_response.get('KeyCount', 0)
            
            # ë¶„ì„ ê²°ê³¼ íŒŒì¼ ìˆ˜
            analysis_response = self.s3_client.list_objects_v2(
                Bucket=self.bucket_name,
                Prefix='analysis/'
            )
            stats['analysis_count'] = analysis_response.get('KeyCount', 0)
            
            # ì´ ì €ì¥ ìš©ëŸ‰ (ê·¼ì‚¬ì¹˜)
            total_size = 0
            if 'Contents' in backup_response:
                total_size += sum(obj['Size'] for obj in backup_response['Contents'])
            if 'Contents' in analysis_response:
                total_size += sum(obj['Size'] for obj in analysis_response['Contents'])
            
            stats['total_size_mb'] = round(total_size / (1024 * 1024), 2)
            
            return stats
            
        except Exception as e:
            logger.error(f"í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return {'available': False, 'error': str(e)}

class LocalStorageManager:
    """ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ ê´€ë¦¬ í´ë˜ìŠ¤ (í´ë¼ìš°ë“œ ëŒ€ì•ˆ)"""
    
    def __init__(self, storage_path: str = "data/storage"):
        """
        ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        
        Args:
            storage_path: ë¡œì»¬ ì €ì¥ì†Œ ê²½ë¡œ
        """
        self.storage_path = storage_path
        os.makedirs(storage_path, exist_ok=True)
        os.makedirs(os.path.join(storage_path, 'backups'), exist_ok=True)
        os.makedirs(os.path.join(storage_path, 'analysis'), exist_ok=True)
    
    def backup_database(self, db_path: str, backup_name: Optional[str] = None) -> bool:
        """
        ë°ì´í„°ë² ì´ìŠ¤ ë¡œì»¬ ë°±ì—…
        
        Args:
            db_path: ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ê²½ë¡œ
            backup_name: ë°±ì—… íŒŒì¼ ì´ë¦„
            
        Returns:
            ë°±ì—… ì„±ê³µ ì—¬ë¶€
        """
        if not os.path.exists(db_path):
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {db_path}")
            return False
        
        if not backup_name:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_name = f"database_backup_{timestamp}.db"
        
        try:
            import shutil
            backup_path = os.path.join(self.storage_path, 'backups', backup_name)
            shutil.copy2(db_path, backup_path)
            
            logger.info(f"ë¡œì»¬ ë°±ì—… ì™„ë£Œ: {backup_path}")
            return True
            
        except Exception as e:
            logger.error(f"ë¡œì»¬ ë°±ì—… ì‹¤íŒ¨: {str(e)}")
            return False
    
    def save_analysis_result(self, analysis_data: Dict[str, Any], 
                           symbol: str, analysis_type: str) -> bool:
        """
        ë¶„ì„ ê²°ê³¼ ë¡œì»¬ ì €ì¥
        
        Args:
            analysis_data: ë¶„ì„ ê²°ê³¼ ë°ì´í„°
            symbol: ì£¼ì‹ ì‹¬ë³¼
            analysis_type: ë¶„ì„ íƒ€ì…
            
        Returns:
            ì €ì¥ ì„±ê³µ ì—¬ë¶€
        """
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # ì‹¬ë³¼ë³„ ë””ë ‰í† ë¦¬ ìƒì„±
            symbol_dir = os.path.join(self.storage_path, 'analysis', symbol)
            os.makedirs(symbol_dir, exist_ok=True)
            
            # íŒŒì¼ ì €ì¥
            filename = f"{analysis_type}_{timestamp}.json"
            filepath = os.path.join(symbol_dir, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(analysis_data, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ë¶„ì„ ê²°ê³¼ ë¡œì»¬ ì €ì¥ ì™„ë£Œ: {filepath}")
            return True
            
        except Exception as e:
            logger.error(f"ë¶„ì„ ê²°ê³¼ ë¡œì»¬ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            return False

# í…ŒìŠ¤íŠ¸ ë° ì˜ˆì œ ì‹¤í–‰
if __name__ == "__main__":
    print("=== AI Stock Trading System - Cloud Storage Manager ===")
    
    # ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ ë§¤ë‹ˆì € í…ŒìŠ¤íŠ¸
    local_storage = LocalStorageManager()
    
    # í…ŒìŠ¤íŠ¸ ë¶„ì„ ë°ì´í„°
    test_analysis = {
        'symbol': 'AAPL',
        'prediction': 'BUY',
        'confidence': 0.85,
        'reasoning': 'Strong technical indicators and positive sentiment',
        'timestamp': datetime.now().isoformat()
    }
    
    # ë¡œì»¬ ì €ì¥ í…ŒìŠ¤íŠ¸
    local_success = local_storage.save_analysis_result(
        test_analysis, 'AAPL', 'optimistic_analysis'
    )
    print(f"âœ… ë¡œì»¬ ì €ì¥ í…ŒìŠ¤íŠ¸: {'ì„±ê³µ' if local_success else 'ì‹¤íŒ¨'}")
    
    # ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… í…ŒìŠ¤íŠ¸
    db_path = "data/stock_data.db"
    if os.path.exists(db_path):
        backup_success = local_storage.backup_database(db_path)
        print(f"âœ… ë¡œì»¬ ë°±ì—… í…ŒìŠ¤íŠ¸: {'ì„±ê³µ' if backup_success else 'ì‹¤íŒ¨'}")
    
    # í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€ ë§¤ë‹ˆì € í…ŒìŠ¤íŠ¸ (ìê²©ì¦ëª…ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ)
    cloud_storage = CloudStorageManager()
    
    if cloud_storage.storage_available:
        print("â˜ï¸ í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€ ì‚¬ìš© ê°€ëŠ¥")
        
        # ë²„í‚· ìƒì„± í…ŒìŠ¤íŠ¸
        bucket_created = cloud_storage.create_bucket_if_not_exists()
        print(f"âœ… ë²„í‚· ìƒì„±/í™•ì¸: {'ì„±ê³µ' if bucket_created else 'ì‹¤íŒ¨'}")
        
        # í´ë¼ìš°ë“œ í†µê³„
        stats = cloud_storage.get_cloud_storage_stats()
        print(f"ğŸ“Š í´ë¼ìš°ë“œ í†µê³„: {stats}")
        
    else:
        print("âš ï¸ í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€ ì‚¬ìš© ë¶ˆê°€ (ìê²©ì¦ëª… í•„ìš”)")
        print("ğŸ’¡ ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ë¥¼ ëŒ€ì•ˆìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
