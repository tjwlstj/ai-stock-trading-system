"""
AI Stock Trading System - Cloud Storage Module (Fixed)
í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€ ì—°ë™ ë° ë°ì´í„° ë°±ì—… ëª¨ë“ˆ (ìê²©ì¦ëª… ì˜¤ë¥˜ ì²˜ë¦¬ ê°œì„ )
"""

import os
import json
import sqlite3
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import logging

logger = logging.getLogger(__name__)

class CloudStorageManager:
    """í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€ ê´€ë¦¬ í´ë˜ìŠ¤ (ì‹œë®¬ë ˆì´ì…˜)"""
    
    def __init__(self, bucket_name: str = "ai-stock-trading-data", 
                 aws_access_key: Optional[str] = None,
                 aws_secret_key: Optional[str] = None,
                 region: str = "us-east-1"):
        """
        í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        
        Args:
            bucket_name: S3 ë²„í‚· ì´ë¦„
            aws_access_key: AWS ì•¡ì„¸ìŠ¤ í‚¤
            aws_secret_key: AWS ì‹œí¬ë¦¿ í‚¤
            region: AWS ë¦¬ì „
        """
        self.bucket_name = bucket_name
        self.region = region
        
        # AWS ìê²©ì¦ëª… í™•ì¸
        aws_key = aws_access_key or os.getenv('AWS_ACCESS_KEY_ID')
        aws_secret = aws_secret_key or os.getenv('AWS_SECRET_ACCESS_KEY')
        
        if aws_key and aws_secret:
            try:
                import boto3
                self.s3_client = boto3.client(
                    's3',
                    aws_access_key_id=aws_key,
                    aws_secret_access_key=aws_secret,
                    region_name=region
                )
                self.storage_available = True
                logger.info("í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€ ì—°ê²° ì„±ê³µ")
            except Exception as e:
                logger.warning(f"í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€ ì—°ê²° ì‹¤íŒ¨: {str(e)}")
                self.s3_client = None
                self.storage_available = False
        else:
            logger.info("AWS ìê²©ì¦ëª…ì´ ì—†ì–´ ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤")
            self.s3_client = None
            self.storage_available = False
            
        # ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ ëŒ€ì•ˆ ì„¤ì •
        self.local_storage = LocalStorageManager()
    
    def upload_database_backup(self, db_path: str, backup_name: Optional[str] = None) -> bool:
        """
        ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… (í´ë¼ìš°ë“œ ë˜ëŠ” ë¡œì»¬)
        
        Args:
            db_path: ë¡œì»¬ ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ê²½ë¡œ
            backup_name: ë°±ì—… íŒŒì¼ ì´ë¦„
            
        Returns:
            ì—…ë¡œë“œ ì„±ê³µ ì—¬ë¶€
        """
        if self.storage_available:
            return self._upload_to_cloud(db_path, backup_name)
        else:
            return self.local_storage.backup_database(db_path, backup_name)
    
    def _upload_to_cloud(self, db_path: str, backup_name: Optional[str] = None) -> bool:
        """ì‹¤ì œ í´ë¼ìš°ë“œ ì—…ë¡œë“œ (AWS ìê²©ì¦ëª…ì´ ìˆëŠ” ê²½ìš°)"""
        if not os.path.exists(db_path):
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {db_path}")
            return False
        
        if not backup_name:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_name = f"database_backup_{timestamp}.db"
        
        try:
            s3_key = f"backups/{backup_name}"
            self.s3_client.upload_file(db_path, self.bucket_name, s3_key)
            logger.info(f"í´ë¼ìš°ë“œ ë°±ì—… ì—…ë¡œë“œ ì„±ê³µ: {s3_key}")
            return True
        except Exception as e:
            logger.error(f"í´ë¼ìš°ë“œ ë°±ì—… ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def upload_analysis_results(self, analysis_data: Dict[str, Any], 
                              symbol: str, analysis_type: str) -> bool:
        """
        ë¶„ì„ ê²°ê³¼ ì—…ë¡œë“œ (í´ë¼ìš°ë“œ ë˜ëŠ” ë¡œì»¬)
        
        Args:
            analysis_data: ë¶„ì„ ê²°ê³¼ ë°ì´í„°
            symbol: ì£¼ì‹ ì‹¬ë³¼
            analysis_type: ë¶„ì„ íƒ€ì…
            
        Returns:
            ì—…ë¡œë“œ ì„±ê³µ ì—¬ë¶€
        """
        if self.storage_available:
            return self._upload_analysis_to_cloud(analysis_data, symbol, analysis_type)
        else:
            return self.local_storage.save_analysis_result(analysis_data, symbol, analysis_type)
    
    def _upload_analysis_to_cloud(self, analysis_data: Dict[str, Any], 
                                symbol: str, analysis_type: str) -> bool:
        """ì‹¤ì œ í´ë¼ìš°ë“œ ë¶„ì„ ê²°ê³¼ ì—…ë¡œë“œ"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            s3_key = f"analysis/{symbol}/{analysis_type}_{timestamp}.json"
            
            json_data = json.dumps(analysis_data, indent=2, ensure_ascii=False)
            
            self.s3_client.put_object(
                Bucket=self.bucket_name,
                Key=s3_key,
                Body=json_data.encode('utf-8'),
                ContentType='application/json'
            )
            
            logger.info(f"í´ë¼ìš°ë“œ ë¶„ì„ ê²°ê³¼ ì—…ë¡œë“œ ì„±ê³µ: {s3_key}")
            return True
        except Exception as e:
            logger.error(f"í´ë¼ìš°ë“œ ë¶„ì„ ê²°ê³¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def get_storage_stats(self) -> Dict[str, Any]:
        """
        ìŠ¤í† ë¦¬ì§€ í†µê³„ ì •ë³´ ë°˜í™˜
        
        Returns:
            í†µê³„ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        if self.storage_available:
            return self._get_cloud_stats()
        else:
            return self.local_storage.get_storage_stats()
    
    def _get_cloud_stats(self) -> Dict[str, Any]:
        """í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€ í†µê³„"""
        try:
            stats = {'type': 'cloud', 'available': True}
            
            # ë°±ì—… íŒŒì¼ ìˆ˜
            backup_response = self.s3_client.list_objects_v2(
                Bucket=self.bucket_name,
                Prefix='backups/'
            )
            stats['backup_count'] = backup_response.get('KeyCount', 0)
            
            # ë¶„ì„ ê²°ê³¼ íŒŒì¼ ìˆ˜
            analysis_response = self.s3_client.list_objects_v2(
                Bucket=self.bucket_name,
                Prefix='analysis/'
            )
            stats['analysis_count'] = analysis_response.get('KeyCount', 0)
            
            return stats
        except Exception as e:
            logger.error(f"í´ë¼ìš°ë“œ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return {'type': 'cloud', 'available': False, 'error': str(e)}

class LocalStorageManager:
    """ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, storage_path: str = "data/storage"):
        """
        ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        
        Args:
            storage_path: ë¡œì»¬ ì €ì¥ì†Œ ê²½ë¡œ
        """
        self.storage_path = storage_path
        os.makedirs(storage_path, exist_ok=True)
        os.makedirs(os.path.join(storage_path, 'backups'), exist_ok=True)
        os.makedirs(os.path.join(storage_path, 'analysis'), exist_ok=True)
    
    def backup_database(self, db_path: str, backup_name: Optional[str] = None) -> bool:
        """
        ë°ì´í„°ë² ì´ìŠ¤ ë¡œì»¬ ë°±ì—…
        
        Args:
            db_path: ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ê²½ë¡œ
            backup_name: ë°±ì—… íŒŒì¼ ì´ë¦„
            
        Returns:
            ë°±ì—… ì„±ê³µ ì—¬ë¶€
        """
        if not os.path.exists(db_path):
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {db_path}")
            return False
        
        if not backup_name:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_name = f"database_backup_{timestamp}.db"
        
        try:
            import shutil
            backup_path = os.path.join(self.storage_path, 'backups', backup_name)
            shutil.copy2(db_path, backup_path)
            
            logger.info(f"ë¡œì»¬ ë°±ì—… ì™„ë£Œ: {backup_path}")
            return True
        except Exception as e:
            logger.error(f"ë¡œì»¬ ë°±ì—… ì‹¤íŒ¨: {str(e)}")
            return False
    
    def save_analysis_result(self, analysis_data: Dict[str, Any], 
                           symbol: str, analysis_type: str) -> bool:
        """
        ë¶„ì„ ê²°ê³¼ ë¡œì»¬ ì €ì¥
        
        Args:
            analysis_data: ë¶„ì„ ê²°ê³¼ ë°ì´í„°
            symbol: ì£¼ì‹ ì‹¬ë³¼
            analysis_type: ë¶„ì„ íƒ€ì…
            
        Returns:
            ì €ì¥ ì„±ê³µ ì—¬ë¶€
        """
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # ì‹¬ë³¼ë³„ ë””ë ‰í† ë¦¬ ìƒì„±
            symbol_dir = os.path.join(self.storage_path, 'analysis', symbol)
            os.makedirs(symbol_dir, exist_ok=True)
            
            # íŒŒì¼ ì €ì¥
            filename = f"{analysis_type}_{timestamp}.json"
            filepath = os.path.join(symbol_dir, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(analysis_data, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ë¶„ì„ ê²°ê³¼ ë¡œì»¬ ì €ì¥ ì™„ë£Œ: {filepath}")
            return True
        except Exception as e:
            logger.error(f"ë¶„ì„ ê²°ê³¼ ë¡œì»¬ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def get_storage_stats(self) -> Dict[str, Any]:
        """
        ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ í†µê³„ ì •ë³´
        
        Returns:
            í†µê³„ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        stats = {'type': 'local', 'available': True}
        
        try:
            # ë°±ì—… íŒŒì¼ ìˆ˜
            backup_dir = os.path.join(self.storage_path, 'backups')
            if os.path.exists(backup_dir):
                stats['backup_count'] = len([f for f in os.listdir(backup_dir) 
                                           if f.endswith('.db')])
            else:
                stats['backup_count'] = 0
            
            # ë¶„ì„ ê²°ê³¼ íŒŒì¼ ìˆ˜
            analysis_dir = os.path.join(self.storage_path, 'analysis')
            analysis_count = 0
            if os.path.exists(analysis_dir):
                for symbol_dir in os.listdir(analysis_dir):
                    symbol_path = os.path.join(analysis_dir, symbol_dir)
                    if os.path.isdir(symbol_path):
                        analysis_count += len([f for f in os.listdir(symbol_path) 
                                             if f.endswith('.json')])
            stats['analysis_count'] = analysis_count
            
            # ì´ ì €ì¥ ìš©ëŸ‰
            total_size = 0
            for root, dirs, files in os.walk(self.storage_path):
                for file in files:
                    filepath = os.path.join(root, file)
                    total_size += os.path.getsize(filepath)
            
            stats['total_size_mb'] = round(total_size / (1024 * 1024), 2)
            
        except Exception as e:
            logger.error(f"ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            stats['error'] = str(e)
        
        return stats
    
    def load_analysis_results(self, symbol: str, limit: int = 10) -> List[Dict[str, Any]]:
        """
        ë¡œì»¬ì—ì„œ ë¶„ì„ ê²°ê³¼ ë¡œë“œ
        
        Args:
            symbol: ì£¼ì‹ ì‹¬ë³¼
            limit: ìµœëŒ€ ë¡œë“œ ê°œìˆ˜
            
        Returns:
            ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        results = []
        
        try:
            symbol_dir = os.path.join(self.storage_path, 'analysis', symbol)
            
            if not os.path.exists(symbol_dir):
                return results
            
            # íŒŒì¼ ëª©ë¡ì„ ìˆ˜ì • ì‹œê°„ ìˆœìœ¼ë¡œ ì •ë ¬
            files = []
            for filename in os.listdir(symbol_dir):
                if filename.endswith('.json'):
                    filepath = os.path.join(symbol_dir, filename)
                    mtime = os.path.getmtime(filepath)
                    files.append((mtime, filepath, filename))
            
            # ìµœì‹  ìˆœìœ¼ë¡œ ì •ë ¬
            files.sort(reverse=True)
            
            # ì œí•œëœ ê°œìˆ˜ë§Œí¼ ë¡œë“œ
            for _, filepath, filename in files[:limit]:
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    results.append({
                        'filename': filename,
                        'filepath': filepath,
                        'data': data,
                        'modified_time': datetime.fromtimestamp(os.path.getmtime(filepath))
                    })
                except Exception as e:
                    logger.error(f"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ {filepath}: {str(e)}")
            
        except Exception as e:
            logger.error(f"ë¶„ì„ ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        
        return results

# í…ŒìŠ¤íŠ¸ ë° ì˜ˆì œ ì‹¤í–‰
if __name__ == "__main__":
    print("=== AI Stock Trading System - Cloud Storage Manager (Fixed) ===")
    
    # í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€ ë§¤ë‹ˆì € í…ŒìŠ¤íŠ¸
    cloud_storage = CloudStorageManager()
    
    # í…ŒìŠ¤íŠ¸ ë¶„ì„ ë°ì´í„°
    test_analysis = {
        'symbol': 'AAPL',
        'prediction': 'BUY',
        'confidence': 0.85,
        'reasoning': 'Strong technical indicators and positive sentiment',
        'timestamp': datetime.now().isoformat()
    }
    
    # ë¶„ì„ ê²°ê³¼ ì €ì¥ í…ŒìŠ¤íŠ¸
    analysis_success = cloud_storage.upload_analysis_results(
        test_analysis, 'AAPL', 'optimistic_analysis'
    )
    print(f"âœ… ë¶„ì„ ê²°ê³¼ ì €ì¥: {'ì„±ê³µ' if analysis_success else 'ì‹¤íŒ¨'}")
    
    # ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… í…ŒìŠ¤íŠ¸
    db_path = "data/stock_data.db"
    if os.path.exists(db_path):
        backup_success = cloud_storage.upload_database_backup(db_path)
        print(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…: {'ì„±ê³µ' if backup_success else 'ì‹¤íŒ¨'}")
    else:
        print("âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ")
    
    # ìŠ¤í† ë¦¬ì§€ í†µê³„
    stats = cloud_storage.get_storage_stats()
    print(f"\nğŸ“Š ìŠ¤í† ë¦¬ì§€ í†µê³„:")
    print(f"  - íƒ€ì…: {stats.get('type', 'unknown')}")
    print(f"  - ì‚¬ìš© ê°€ëŠ¥: {stats.get('available', False)}")
    print(f"  - ë°±ì—… íŒŒì¼: {stats.get('backup_count', 0)}ê°œ")
    print(f"  - ë¶„ì„ ê²°ê³¼: {stats.get('analysis_count', 0)}ê°œ")
    
    if 'total_size_mb' in stats:
        print(f"  - ì´ ìš©ëŸ‰: {stats['total_size_mb']} MB")
    
    # ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ì—ì„œ ë¶„ì„ ê²°ê³¼ ë¡œë“œ í…ŒìŠ¤íŠ¸
    if not cloud_storage.storage_available:
        print(f"\nğŸ“ AAPL ë¶„ì„ ê²°ê³¼ ë¡œë“œ í…ŒìŠ¤íŠ¸:")
        local_results = cloud_storage.local_storage.load_analysis_results('AAPL', limit=3)
        
        if local_results:
            for i, result in enumerate(local_results, 1):
                print(f"  {i}. {result['filename']} - {result['modified_time']}")
        else:
            print("  ì €ì¥ëœ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    print(f"\nğŸ’¡ {'í´ë¼ìš°ë“œ' if cloud_storage.storage_available else 'ë¡œì»¬'} ìŠ¤í† ë¦¬ì§€ë¥¼ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤.")
